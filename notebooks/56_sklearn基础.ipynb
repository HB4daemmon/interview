{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "7fdceb6f",
      "metadata": {},
      "source": [
        "\\\n",
        "            # 56. 机器学习基础：scikit-learn（sklearn）（scikit-learn Fundamentals）\n",
        "\n",
        "            目标：掌握用 sklearn 完成一个典型机器学习项目的最小闭环：\n",
        "- 数据集与特征/标签\n",
        "- 训练/验证拆分、避免数据泄漏\n",
        "- Pipeline（预处理+模型）\n",
        "- 评估指标、交叉验证、调参\n",
        "- 模型保存与上线前检查（概念）\n",
        "本章依赖 `scikit-learn`（导入包名为 sklearn）；若未安装会提示安装命令并跳过相关演示。\n",
        "\n",
        "            > 约定：Python 3.8；示例尽量只用标准库；代码块可直接运行（第三方依赖会做可选降级）。\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c5759900",
      "metadata": {},
      "source": [
        "## 前置知识\n",
        "\n",
        "- NumPy/Pandas 基础（建议）\n",
        "- RESTful/缓存/工程化基础（了解更佳）\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f243259e",
      "metadata": {},
      "source": [
        "## 知识点地图\n",
        "\n",
        "- 1. sklearn 心智模型：Estimator / Transformer / Pipeline\n",
        "- 2. 安装与导入（可选依赖）\n",
        "- 3. 数据集：用 Iris 演示分类问题（最小闭环）\n",
        "- 4. 数据泄漏（核心坑）：为什么要用 Pipeline\n",
        "- 5. Pipeline：StandardScaler + LogisticRegression\n",
        "- 6. 评估：交叉验证（cross_val_score）\n",
        "- 7. 调参：GridSearchCV（入门）\n",
        "- 8. 模型保存：pickle/joblib（概念 + 可选代码）\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ef60cb47",
      "metadata": {},
      "source": [
        "## 自检清单（学完打勾）\n",
        "\n",
        "- [ ] 理解监督学习的基本对象：X（特征）、y（标签）\n",
        "- [ ] 会做 train/test split 并设置 random_state\n",
        "- [ ] 会用 Pipeline 把预处理与模型绑在一起（避免泄漏）\n",
        "- [ ] 会用常见指标评估分类/回归（accuracy/F1/MSE 等）\n",
        "- [ ] 会做交叉验证与简单网格搜索（GridSearchCV）\n",
        "- [ ] 知道模型持久化（保存/加载）与版本管理要点（概念）\n"
      ]
    },
    {
      "cell_type": "code",
      "id": "525c4e9b",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\\\n",
        "from pathlib import Path\n",
        "\n",
        "ART = Path('_nb_artifacts')\n",
        "ART.mkdir(exist_ok=True)\n",
        "print('artifacts dir:', ART.resolve())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ba40370c",
      "metadata": {},
      "source": [
        "## 知识点 1：sklearn 心智模型：Estimator / Transformer / Pipeline\n",
        "\n",
        "sklearn 的核心接口统一：\n",
        "- Estimator：`fit(X, y)` 训练\n",
        "- Predictor：`predict(X)` 预测（很多 estimator 同时是 predictor）\n",
        "- Transformer：`fit_transform(X)` 做特征变换（StandardScaler、OneHotEncoder...）\n",
        "\n",
        "Pipeline 把多个步骤串起来：\n",
        "- 预处理（transform）\n",
        "- 模型（predict）\n",
        "\n",
        "价值：可复现、可交叉验证、避免数据泄漏。\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "32b15895",
      "metadata": {},
      "source": [
        "## 知识点 2：安装与导入（可选依赖）\n",
        "\n",
        "安装：\n",
        "- `pip install scikit-learn`\n",
        "\n",
        "注意：包名是 `scikit-learn`，导入名是 `sklearn`。\n"
      ]
    },
    {
      "cell_type": "code",
      "id": "91b4a3bf",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "try:\n",
        "    import sklearn\n",
        "except Exception as e:\n",
        "    sklearn = None\n",
        "    print('sklearn not available:', type(e).__name__, e)\n",
        "    print('install: pip install scikit-learn')\n",
        "else:\n",
        "    print('sklearn version:', sklearn.__version__)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "32787ebb",
      "metadata": {},
      "source": [
        "## 知识点 3：数据集：用 Iris 演示分类问题（最小闭环）\n",
        "\n",
        "用内置 iris 数据集：\n",
        "- X：四个花萼/花瓣特征\n",
        "- y：三类鸢尾花\n",
        "\n",
        "流程：\n",
        "1) 拆分训练/测试\n",
        "2) 训练模型\n",
        "3) 评估指标\n"
      ]
    },
    {
      "cell_type": "code",
      "id": "6d590c4d",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "try:\n",
        "    from sklearn.datasets import load_iris\n",
        "    from sklearn.model_selection import train_test_split\n",
        "    from sklearn.linear_model import LogisticRegression\n",
        "    from sklearn.metrics import classification_report, accuracy_score\n",
        "except Exception as e:\n",
        "    print('install scikit-learn to run this cell:', type(e).__name__, e)\n",
        "else:\n",
        "    X, y = load_iris(return_X_y=True)\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42, stratify=y)\n",
        "\n",
        "    clf = LogisticRegression(max_iter=200)\n",
        "    clf.fit(X_train, y_train)\n",
        "    pred = clf.predict(X_test)\n",
        "\n",
        "    print('accuracy:', round(accuracy_score(y_test, pred), 4))\n",
        "    print(classification_report(y_test, pred))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eccfcb46",
      "metadata": {},
      "source": [
        "## 知识点 4：数据泄漏（核心坑）：为什么要用 Pipeline\n",
        "\n",
        "数据泄漏：把“测试集信息”不小心用进训练过程，导致评估虚高。\n",
        "\n",
        "典型泄漏：\n",
        "- 在全量数据上 fit scaler/encoder，然后再 split\n",
        "\n",
        "正确做法：\n",
        "- 把 scaler/encoder 放进 Pipeline\n",
        "- 交叉验证/网格搜索时也对每个 fold 单独 fit\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e5faf2bc",
      "metadata": {},
      "source": [
        "## 知识点 5：Pipeline：StandardScaler + LogisticRegression\n",
        "\n",
        "标准化 + 线性模型是很常见的 baseline。\n",
        "\n",
        "注意：\n",
        "- `StandardScaler` 必须只在训练数据上 fit。\n",
        "- Pipeline 会自动保证这一点。\n"
      ]
    },
    {
      "cell_type": "code",
      "id": "d1b32bef",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "try:\n",
        "    from sklearn.datasets import load_iris\n",
        "    from sklearn.model_selection import train_test_split\n",
        "    from sklearn.pipeline import Pipeline\n",
        "    from sklearn.preprocessing import StandardScaler\n",
        "    from sklearn.linear_model import LogisticRegression\n",
        "    from sklearn.metrics import accuracy_score\n",
        "except Exception as e:\n",
        "    print('install scikit-learn to run this cell:', type(e).__name__, e)\n",
        "else:\n",
        "    X, y = load_iris(return_X_y=True)\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=0, stratify=y)\n",
        "\n",
        "    pipe = Pipeline([\n",
        "        ('scaler', StandardScaler()),\n",
        "        ('clf', LogisticRegression(max_iter=200)),\n",
        "    ])\n",
        "    pipe.fit(X_train, y_train)\n",
        "    pred = pipe.predict(X_test)\n",
        "    print('accuracy:', round(accuracy_score(y_test, pred), 4))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4ff5c7cc",
      "metadata": {},
      "source": [
        "## 知识点 6：评估：交叉验证（cross_val_score）\n",
        "\n",
        "一次 train/test split 的结果可能不稳定。\n",
        "\n",
        "交叉验证（CV）：\n",
        "- 把训练数据分成 k 份\n",
        "- 轮流用 k-1 份训练、1 份验证\n",
        "- 得到更稳健的评估分数\n"
      ]
    },
    {
      "cell_type": "code",
      "id": "02aaa479",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "try:\n",
        "    from sklearn.datasets import load_iris\n",
        "    from sklearn.model_selection import cross_val_score\n",
        "    from sklearn.pipeline import Pipeline\n",
        "    from sklearn.preprocessing import StandardScaler\n",
        "    from sklearn.linear_model import LogisticRegression\n",
        "except Exception as e:\n",
        "    print('install scikit-learn to run this cell:', type(e).__name__, e)\n",
        "else:\n",
        "    X, y = load_iris(return_X_y=True)\n",
        "    pipe = Pipeline([\n",
        "        ('scaler', StandardScaler()),\n",
        "        ('clf', LogisticRegression(max_iter=300)),\n",
        "    ])\n",
        "    scores = cross_val_score(pipe, X, y, cv=5)\n",
        "    print('cv scores:', scores)\n",
        "    print('mean:', scores.mean(), 'std:', scores.std())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b578de9b",
      "metadata": {},
      "source": [
        "## 知识点 7：调参：GridSearchCV（入门）\n",
        "\n",
        "调参要点：\n",
        "- 参数搜索在训练集内部进行（CV），不要偷看测试集。\n",
        "- 搜索空间不要太大：先粗后细。\n",
        "\n",
        "示例：对 C（正则强度）做网格搜索。\n"
      ]
    },
    {
      "cell_type": "code",
      "id": "fd3eea46",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "try:\n",
        "    from sklearn.datasets import load_iris\n",
        "    from sklearn.model_selection import GridSearchCV\n",
        "    from sklearn.pipeline import Pipeline\n",
        "    from sklearn.preprocessing import StandardScaler\n",
        "    from sklearn.linear_model import LogisticRegression\n",
        "except Exception as e:\n",
        "    print('install scikit-learn to run this cell:', type(e).__name__, e)\n",
        "else:\n",
        "    X, y = load_iris(return_X_y=True)\n",
        "    pipe = Pipeline([\n",
        "        ('scaler', StandardScaler()),\n",
        "        ('clf', LogisticRegression(max_iter=500)),\n",
        "    ])\n",
        "\n",
        "    gs = GridSearchCV(\n",
        "        pipe,\n",
        "        param_grid={'clf__C': [0.1, 1.0, 10.0]},\n",
        "        cv=5,\n",
        "        n_jobs=None,\n",
        "    )\n",
        "    gs.fit(X, y)\n",
        "    print('best params:', gs.best_params_)\n",
        "    print('best score:', gs.best_score_)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "48a4bde7",
      "metadata": {},
      "source": [
        "## 知识点 8：模型保存：pickle/joblib（概念 + 可选代码）\n",
        "\n",
        "模型上线需要：\n",
        "- 保存训练好的 pipeline（包含预处理）\n",
        "- 记录版本：数据版本/代码版本/参数版本\n",
        "- 上线前校验：输入 schema、输出范围、回归测试\n",
        "\n",
        "保存方式：\n",
        "- `joblib.dump`（sklearn 官方常用）\n",
        "- `pickle`（通用，但注意安全：不要加载不可信 pickle）\n"
      ]
    },
    {
      "cell_type": "code",
      "id": "86e40249",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "\n",
        "try:\n",
        "    import joblib\n",
        "    from sklearn.datasets import load_iris\n",
        "    from sklearn.pipeline import Pipeline\n",
        "    from sklearn.preprocessing import StandardScaler\n",
        "    from sklearn.linear_model import LogisticRegression\n",
        "except Exception as e:\n",
        "    print('optional deps missing:', type(e).__name__, e)\n",
        "    print('install: pip install scikit-learn joblib')\n",
        "else:\n",
        "    X, y = load_iris(return_X_y=True)\n",
        "    pipe = Pipeline([\n",
        "        ('scaler', StandardScaler()),\n",
        "        ('clf', LogisticRegression(max_iter=300)),\n",
        "    ])\n",
        "    pipe.fit(X, y)\n",
        "\n",
        "    ART = Path('_nb_artifacts')\n",
        "    ART.mkdir(exist_ok=True)\n",
        "    path = ART / 'iris_pipe.joblib'\n",
        "    joblib.dump(pipe, path)\n",
        "    print('saved to', path)\n",
        "\n",
        "    loaded = joblib.load(path)\n",
        "    print('predict first 3:', loaded.predict(X[:3]))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f5548bf5",
      "metadata": {},
      "source": [
        "## 常见坑\n",
        "\n",
        "- 数据泄漏：预处理在全量数据上 fit\n",
        "- 只看训练集分数：没做验证/测试，过拟合看不出来\n",
        "- 调参偷看测试集：导致指标虚高\n",
        "- merge 数据后行数不对：标签对齐错误（常见于表连接）\n",
        "- 模型持久化加载不安全：不要加载不可信 pickle/joblib\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e5e27013",
      "metadata": {},
      "source": [
        "## 综合小案例：构建一个“可上线”的分类 Pipeline（含输入校验思路）\n",
        "\n",
        "目标：\n",
        "- 选一个数据集（iris 或你自己的 CSV）\n",
        "- 构建 pipeline：预处理 + 模型\n",
        "- 用 CV 评估并调参\n",
        "- 保存模型到 `_nb_artifacts`\n",
        "- 写一份“上线检查清单”：\n",
        "  - 输入字段/类型/范围校验\n",
        "  - 版本号（模型/数据/特征）\n",
        "  - 监控指标（延迟、错误率、分布漂移）\n"
      ]
    },
    {
      "cell_type": "code",
      "id": "0cce6f09",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 建议：把检查清单写成 Markdown 文档并放进项目仓库。\n",
        "# 本 cell 不运行代码。\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d2edbeb1",
      "metadata": {},
      "source": [
        "## 自测题（不写代码也能回答）\n",
        "\n",
        "- 为什么推荐使用 Pipeline？它如何帮助避免数据泄漏？\n",
        "- 交叉验证解决了什么问题？\n",
        "- GridSearchCV 应该在什么时候用？为什么不应该在测试集上调参？\n",
        "- 为什么上线时要保存“预处理 + 模型”的整体？\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d5d10bf2",
      "metadata": {},
      "source": [
        "## 练习题（建议写代码）\n",
        "\n",
        "- 把分类任务换成回归（例如 Boston 已弃用，可用自造数据或 diabetes 数据集），并使用 MSE/MAE 评估。\n",
        "- 为 Pipeline 加入特征选择（SelectKBest）并比较效果（了解）。\n",
        "- 写一个 RESTful 预测接口（FastAPI/Flask）加载 joblib 模型并提供 /predict（与框架章节呼应）。\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
