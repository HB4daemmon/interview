{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "fd8dfd70",
      "metadata": {},
      "source": [
        "\\\n",
        "            # 57. 深度学习基础：PyTorch（PyTorch Fundamentals）\n",
        "\n",
        "            目标：掌握 PyTorch 的核心对象与训练套路：Tensor、autograd、nn.Module、Dataset/DataLoader、训练/评估模式、保存/加载。\n",
        "本章依赖 `torch`；若未安装会提示安装命令并跳过演示。\n",
        "提示：Windows 安装 PyTorch 可能需要选择合适的 CUDA/CPU 版本，请以 PyTorch 官方安装指引为准。\n",
        "\n",
        "            > 约定：Python 3.8；示例尽量只用标准库；代码块可直接运行（第三方依赖会做可选降级）。\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f27e839c",
      "metadata": {},
      "source": [
        "## 前置知识\n",
        "\n",
        "- NumPy 基础（建议）\n",
        "- 线性代数/导数（了解更佳）\n",
        "- Python 类/函数基础\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9b1220fb",
      "metadata": {},
      "source": [
        "## 知识点地图\n",
        "\n",
        "- 1. PyTorch 训练的最小闭环\n",
        "- 2. 安装与导入（可选依赖）\n",
        "- 3. Tensor 基础：shape/dtype/device 与广播\n",
        "- 4. autograd：requires_grad 与 backward（梯度）\n",
        "- 5. 定义模型：nn.Module + Linear\n",
        "- 6. 训练循环（核心）：train/eval、loss、optim\n",
        "- 7. Dataset/DataLoader：批量训练与 shuffle\n",
        "- 8. 保存/加载：state_dict（推荐）\n",
        "- 9. 与 sklearn 的关系（理解）：何时用哪个？\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7f1306c6",
      "metadata": {},
      "source": [
        "## 自检清单（学完打勾）\n",
        "\n",
        "- [ ] 理解 Tensor（shape/dtype/device）与基本运算\n",
        "- [ ] 理解 autograd：requires_grad、backward、梯度累积与清零\n",
        "- [ ] 会用 nn.Module 定义模型并用 optim 优化\n",
        "- [ ] 会写最小训练循环（train/eval、loss、step）\n",
        "- [ ] 会用 Dataset/DataLoader 组织数据与 batch\n",
        "- [ ] 会保存/加载 state_dict 并复现实验（seed/版本）\n"
      ]
    },
    {
      "cell_type": "code",
      "id": "065cc1a7",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\\\n",
        "from pathlib import Path\n",
        "\n",
        "ART = Path('_nb_artifacts')\n",
        "ART.mkdir(exist_ok=True)\n",
        "print('artifacts dir:', ART.resolve())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1f7dbc23",
      "metadata": {},
      "source": [
        "## 知识点 1：PyTorch 训练的最小闭环\n",
        "\n",
        "PyTorch 常见训练流程：\n",
        "1) 准备数据（Tensor / Dataset / DataLoader）\n",
        "2) 定义模型（nn.Module）\n",
        "3) 定义损失（loss）与优化器（optim）\n",
        "4) 训练循环：forward -> loss -> backward -> step\n",
        "5) 验证/评估：model.eval() + torch.no_grad()\n",
        "6) 保存模型：state_dict\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2e54b5f3",
      "metadata": {},
      "source": [
        "## 知识点 2：安装与导入（可选依赖）\n",
        "\n",
        "安装（CPU 版示例，具体以官方为准）：\n",
        "- `pip install torch`\n",
        "\n",
        "如果你需要 GPU/CUDA，请按官方安装命令选择对应版本。\n"
      ]
    },
    {
      "cell_type": "code",
      "id": "1380f9db",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "try:\n",
        "    import torch\n",
        "except Exception as e:\n",
        "    torch = None\n",
        "    print('torch not available:', type(e).__name__, e)\n",
        "    print('install: pip install torch')\n",
        "else:\n",
        "    print('torch version:', torch.__version__)\n",
        "    print('cuda available:', torch.cuda.is_available())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6b6ab9df",
      "metadata": {},
      "source": [
        "## 知识点 3：Tensor 基础：shape/dtype/device 与广播\n",
        "\n",
        "- shape：张量形状\n",
        "- dtype：float32/float64/int64...\n",
        "- device：cpu/cuda\n",
        "\n",
        "广播规则与 NumPy 类似，但要注意 device 与 dtype 不一致会报错或产生隐式转换。\n"
      ]
    },
    {
      "cell_type": "code",
      "id": "f9bf63d6",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "try:\n",
        "    import torch\n",
        "except Exception:\n",
        "    print('install torch to run this cell')\n",
        "else:\n",
        "    a = torch.tensor([[1.0, 2.0], [3.0, 4.0]])\n",
        "    b = torch.tensor([10.0, 20.0])\n",
        "    print('a shape', a.shape, 'dtype', a.dtype, 'device', a.device)\n",
        "    print('a + b ->\\n', a + b)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9443b984",
      "metadata": {},
      "source": [
        "## 知识点 4：autograd：requires_grad 与 backward（梯度）\n",
        "\n",
        "- `requires_grad=True`：追踪计算图\n",
        "- `loss.backward()`：反向传播计算梯度\n",
        "\n",
        "关键坑：\n",
        "- 梯度默认会累积（每次 backward 都会累加到 `.grad`），每步需要 `optimizer.zero_grad()`。\n",
        "- 推理阶段要用 `torch.no_grad()` 避免不必要的图与显存/内存占用。\n"
      ]
    },
    {
      "cell_type": "code",
      "id": "af8dbf80",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "try:\n",
        "    import torch\n",
        "except Exception:\n",
        "    print('install torch to run this cell')\n",
        "else:\n",
        "    x = torch.tensor([2.0], requires_grad=True)\n",
        "    y = x * x + 3 * x + 1\n",
        "    y.backward()\n",
        "    print('y:', y.item())\n",
        "    print('dy/dx:', x.grad.item())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "391353d4",
      "metadata": {},
      "source": [
        "## 知识点 5：定义模型：nn.Module + Linear\n",
        "\n",
        "- nn.Module 是所有模型的基类\n",
        "- 层（layer）作为成员变量注册\n",
        "- forward 定义前向计算\n",
        "\n",
        "下面实现一个最小线性回归模型。\n"
      ]
    },
    {
      "cell_type": "code",
      "id": "43625937",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "try:\n",
        "    import torch\n",
        "    import torch.nn as nn\n",
        "except Exception:\n",
        "    print('install torch to run this cell')\n",
        "else:\n",
        "    class LinReg(nn.Module):\n",
        "        def __init__(self):\n",
        "            super().__init__()\n",
        "            self.linear = nn.Linear(1, 1)\n",
        "\n",
        "        def forward(self, x):\n",
        "            return self.linear(x)\n",
        "\n",
        "    m = LinReg()\n",
        "    x = torch.randn(3, 1)\n",
        "    y = m(x)\n",
        "    print('x shape', x.shape, 'y shape', y.shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bcc6d813",
      "metadata": {},
      "source": [
        "## 知识点 6：训练循环（核心）：train/eval、loss、optim\n",
        "\n",
        "训练循环的关键步骤：\n",
        "- `model.train()`：启用训练模式（影响 Dropout/BatchNorm）\n",
        "- forward：`pred = model(x)`\n",
        "- loss：`loss = criterion(pred, y)`\n",
        "- backward：`optimizer.zero_grad(); loss.backward(); optimizer.step()`\n",
        "\n",
        "评估：\n",
        "- `model.eval()` + `torch.no_grad()`\n"
      ]
    },
    {
      "cell_type": "code",
      "id": "07881920",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "try:\n",
        "    import torch\n",
        "    import torch.nn as nn\n",
        "except Exception:\n",
        "    print('install torch to run this cell')\n",
        "else:\n",
        "    torch.manual_seed(0)\n",
        "\n",
        "    # synthetic data: y = 3x + 2 + noise\n",
        "    N = 200\n",
        "    x = torch.rand(N, 1) * 2 - 1\n",
        "    y = 3 * x + 2 + 0.1 * torch.randn(N, 1)\n",
        "\n",
        "    model = nn.Linear(1, 1)\n",
        "    optim = torch.optim.SGD(model.parameters(), lr=0.1)\n",
        "    loss_fn = nn.MSELoss()\n",
        "\n",
        "    for epoch in range(50):\n",
        "        model.train()\n",
        "        pred = model(x)\n",
        "        loss = loss_fn(pred, y)\n",
        "        optim.zero_grad()\n",
        "        loss.backward()\n",
        "        optim.step()\n",
        "        if (epoch + 1) % 10 == 0:\n",
        "            w = model.weight.item()\n",
        "            b = model.bias.item()\n",
        "            print('epoch', epoch + 1, 'loss', round(loss.item(), 4), 'w', round(w, 3), 'b', round(b, 3))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1881d07b",
      "metadata": {},
      "source": [
        "## 知识点 7：Dataset/DataLoader：批量训练与 shuffle\n",
        "\n",
        "- Dataset：定义 `__len__` 与 `__getitem__`\n",
        "- DataLoader：负责 batch、shuffle、多进程加载（num_workers）\n",
        "\n",
        "注意：Windows 下 num_workers>0 可能需要额外注意（spawn）；入门建议先用 num_workers=0。\n"
      ]
    },
    {
      "cell_type": "code",
      "id": "ec504c79",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "try:\n",
        "    import torch\n",
        "    from torch.utils.data import Dataset, DataLoader\n",
        "    import torch.nn as nn\n",
        "except Exception:\n",
        "    print('install torch to run this cell')\n",
        "else:\n",
        "    class XY(Dataset):\n",
        "        def __init__(self, x, y):\n",
        "            self.x = x\n",
        "            self.y = y\n",
        "        def __len__(self):\n",
        "            return self.x.shape[0]\n",
        "        def __getitem__(self, idx):\n",
        "            return self.x[idx], self.y[idx]\n",
        "\n",
        "    torch.manual_seed(0)\n",
        "    N = 200\n",
        "    x = torch.rand(N, 1) * 2 - 1\n",
        "    y = 3 * x + 2 + 0.1 * torch.randn(N, 1)\n",
        "\n",
        "    ds = XY(x, y)\n",
        "    dl = DataLoader(ds, batch_size=32, shuffle=True, num_workers=0)\n",
        "\n",
        "    model = nn.Linear(1, 1)\n",
        "    optim = torch.optim.SGD(model.parameters(), lr=0.1)\n",
        "    loss_fn = nn.MSELoss()\n",
        "\n",
        "    for epoch in range(10):\n",
        "        model.train()\n",
        "        total = 0.0\n",
        "        for xb, yb in dl:\n",
        "            pred = model(xb)\n",
        "            loss = loss_fn(pred, yb)\n",
        "            optim.zero_grad()\n",
        "            loss.backward()\n",
        "            optim.step()\n",
        "            total += loss.item() * xb.shape[0]\n",
        "        print('epoch', epoch + 1, 'avg_loss', round(total / len(ds), 4))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dc9c3148",
      "metadata": {},
      "source": [
        "## 知识点 8：保存/加载：state_dict（推荐）\n",
        "\n",
        "推荐保存：\n",
        "- `torch.save(model.state_dict(), path)`\n",
        "加载：\n",
        "- `model.load_state_dict(torch.load(path, map_location='cpu'))`\n",
        "\n",
        "注意：\n",
        "- 不建议直接保存整个模型对象（pickle 风险 + 代码变更不兼容）。\n"
      ]
    },
    {
      "cell_type": "code",
      "id": "d6d003ff",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "\n",
        "try:\n",
        "    import torch\n",
        "    import torch.nn as nn\n",
        "except Exception:\n",
        "    print('install torch to run this cell')\n",
        "else:\n",
        "    model = nn.Linear(1, 1)\n",
        "    # fake training result\n",
        "    with torch.no_grad():\n",
        "        model.weight.fill_(3.0)\n",
        "        model.bias.fill_(2.0)\n",
        "\n",
        "    ART = Path('_nb_artifacts')\n",
        "    ART.mkdir(exist_ok=True)\n",
        "    path = ART / 'linreg_state.pt'\n",
        "    torch.save(model.state_dict(), path)\n",
        "    print('saved', path)\n",
        "\n",
        "    m2 = nn.Linear(1, 1)\n",
        "    m2.load_state_dict(torch.load(path, map_location='cpu'))\n",
        "    x = torch.tensor([[1.0]])\n",
        "    print('pred:', m2(x).item())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "56b9d8ed",
      "metadata": {},
      "source": [
        "## 知识点 9：与 sklearn 的关系（理解）：何时用哪个？\n",
        "\n",
        "- sklearn：传统 ML（线性模型、树模型、聚类等）+ 标准化评估工具链，适合结构化数据 baseline。\n",
        "- PyTorch：深度学习/自定义模型/自定义训练循环，适合图像/文本/序列与复杂模型。\n",
        "\n",
        "现实项目常组合：\n",
        "- 用 pandas/sklearn 做特征与 baseline\n",
        "- 用 PyTorch 做深度模型或更复杂的学习器\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "061f9c28",
      "metadata": {},
      "source": [
        "## 常见坑\n",
        "\n",
        "- 忘记 zero_grad：梯度累积导致训练发散/异常\n",
        "- 训练时忘记 model.train()/评估时忘记 model.eval()\n",
        "- 推理没用 torch.no_grad：内存占用变大\n",
        "- device 不一致：cpu tensor 与 cuda model 混用报错\n",
        "- shape 不一致：batch 维度丢失导致 Linear 输入错误\n",
        "- 学习率不合适：太大震荡、太小不收敛\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ea31f84c",
      "metadata": {},
      "source": [
        "## 综合小案例：实现一个二分类（合成数据）并输出准确率\n",
        "\n",
        "目标：\n",
        "- 生成二维点 (x1,x2)，用线性可分规则生成标签\n",
        "- 用 `nn.Sequential(Linear->Sigmoid)` 或 `BCEWithLogitsLoss` 训练\n",
        "- 评估准确率\n",
        "\n",
        "提示：\n",
        "- 用 `BCEWithLogitsLoss`（更稳定），模型输出 logits，不要手动 Sigmoid。\n"
      ]
    },
    {
      "cell_type": "code",
      "id": "f399932a",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "try:\n",
        "    import torch\n",
        "    import torch.nn as nn\n",
        "except Exception:\n",
        "    print('install torch to run this cell')\n",
        "else:\n",
        "    torch.manual_seed(0)\n",
        "    N = 400\n",
        "    X = torch.randn(N, 2)\n",
        "    # linear rule: x1 + x2 > 0 -> 1 else 0\n",
        "    y = (X[:, 0] + X[:, 1] > 0).float().unsqueeze(1)\n",
        "\n",
        "    model = nn.Linear(2, 1)\n",
        "    loss_fn = nn.BCEWithLogitsLoss()\n",
        "    optim = torch.optim.SGD(model.parameters(), lr=0.2)\n",
        "\n",
        "    for epoch in range(50):\n",
        "        logits = model(X)\n",
        "        loss = loss_fn(logits, y)\n",
        "        optim.zero_grad()\n",
        "        loss.backward()\n",
        "        optim.step()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        pred = (torch.sigmoid(model(X)) > 0.5).float()\n",
        "        acc = (pred.eq(y)).float().mean().item()\n",
        "    print('acc:', round(acc, 4))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5213db77",
      "metadata": {},
      "source": [
        "## 自测题（不写代码也能回答）\n",
        "\n",
        "- autograd 的作用是什么？为什么梯度会累积？\n",
        "- model.train() 与 model.eval() 的差异是什么？\n",
        "- 为什么推理阶段要用 torch.no_grad()？\n",
        "- 为什么推荐保存 state_dict 而不是保存整个模型对象？\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "94262cba",
      "metadata": {},
      "source": [
        "## 练习题（建议写代码）\n",
        "\n",
        "- 把 mini_case 改成：训练/验证拆分，并输出验证集准确率。\n",
        "- 给训练循环加入学习率调度（StepLR，了解）。\n",
        "- 用 FastAPI 写一个 /predict 接口加载 state_dict 做推理（与框架章节呼应）。\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
